{"status":"OK","request_id":"6aa9a58b-3893-4cb2-baf5-3a2955210a94","parameters":{"query":"data engineer in ca,usa","page":1,"num_pages":1,"date_posted":"all"},"data":[{"job_id":"1gfJrcXbBvv4FScgAAAAAA==","employer_name":"Saxon Global Inc.","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS2Gv0UzbuWOsg4qC25IEZ9dY9Q5EYuOZubhzHu&s=0","employer_website":"http://www.saxonglobal.com","employer_company_type":null,"employer_linkedin":"https://www.facebook.com/SaxonGlobal/","job_publisher":"Dice.com","job_employment_type":"CONTRACTOR","job_title":"Immediate interview for Data Engineer @ Sunnyvale, CA--Hybrid","job_apply_link":"https://www.dice.com/job-detail/6c9518ed-94cc-43a7-9b37-3c1e705e38f0?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":true,"job_apply_quality_score":0.5644,"apply_options":[{"publisher":"Dice.com","apply_link":"https://www.dice.com/job-detail/6c9518ed-94cc-43a7-9b37-3c1e705e38f0?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":true}],"job_description":"Hello,\n\nI am Mohammed Dastagir with Saxon Global Inc wanted to let you know about the job opportunity for Data Engineer position if interested please share your updated resume along with expecting rate.\n\nJob title: Data Engineer\n\nLocation: Sunnyvale, CA--Hybrid\n\nDuration: Long term\n\nOnly on W2 / H1 transfer\n\nMust have:\n• SCALA, JAVA, AND PYTHON\n• SPARK\n• Virtualization: Looker, Adobe, Or Google Data Studio\n\nJob Description:\n• Will be doing Data Engineering work for a Marketing Technology Platform. Position is 60 percent reporting and 40 percent data engineering.\n• Will be building large scale data pipelines. Need to be proficient in SQL, data, analysis, and reporting.\n• Need to have experience with (looker, Google data studio, or adobe). The resource will be pulling data from structured and unstructured data sources. Then ETL the data using Scala, Python, Java, utilize Spark . Everything is done in a Google Cloud Platform/ Azure environment with usage of Hive tables.\n\nBest Regards\n\nMohammed Dastagir\n\nResource Manager\n\nSaxon Global Inc.\n\np: Ext: 215\n\na:\n\nw: e: dastagir.m","job_is_remote":false,"job_posted_at_timestamp":1724171443,"job_posted_at_datetime_utc":"2024-08-20T16:30:43.000Z","job_city":null,"job_state":"CA","job_country":"US","job_latitude":36.77826,"job_longitude":-119.41793,"job_benefits":null,"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3D1gfJrcXbBvv4FScgAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":"2024-09-21T08:15:35.000Z","job_offer_expiration_timestamp":1726906535,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":null,"experience_mentioned":"true","experience_preferred":"false"},"job_required_skills":["Virtualization","Marketing","Data engineering","SQL","Data Analysis","Reporting","Adobe","Unstructured data","Extract","transform","load","Data","Scala","Python","Java","Apache Spark","Google Cloud","Google Cloud Platform","Microsoft Azure","Apache Hive","EXT","IMG"],"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":"false","degree_preferred":"false","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Need to be proficient in SQL, data, analysis, and reporting","Need to have experience with (looker, Google data studio, or adobe)"],"Responsibilities":["Will be doing Data Engineering work for a Marketing Technology Platform","Position is 60 percent reporting and 40 percent data engineering","Will be building large scale data pipelines"]},"job_job_title":null,"job_posting_language":"en","job_onet_soc":"43411100","job_onet_job_zone":"2","job_occupational_categories":null,"job_naics_code":null,"job_naics_name":null},{"job_id":"NYirA7P21JRzyE_OAAAAAA==","employer_name":"Essex Property Trust","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTp68rtR6eaSvXF5WRls5ODREitFZkni7Cpm6oN&s=0","employer_website":"https://www.essexapartmenthomes.com","employer_company_type":null,"employer_linkedin":"https://www.essexapartmenthomes.com/","job_publisher":"LinkedIn","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https://www.linkedin.com/jobs/view/data-engineer-at-essex-property-trust-4005591007?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.6196,"apply_options":[{"publisher":"LinkedIn","apply_link":"https://www.linkedin.com/jobs/view/data-engineer-at-essex-property-trust-4005591007?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Adzuna","apply_link":"https://www.adzuna.com/details/4834491154?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Jobilize","apply_link":"https://www.jobilize.com/job/us-ca-laguna-niguel-data-engineer-innova-solutions-hiring-now-job?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Job Search In The United States","apply_link":"https://jobradars.com/jobs/view/1780854?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Interlink Jobs","apply_link":"https://www.interlinkjobs.com/jobs/73369629-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"City\n\nIrvine\n\nState\n\nCalifornia\n\nJob Location\n\nIrvine Regional Office (Derian)\n\nPosition Type\n\nRegular\n\nAbout Us\n\nThe Data Platform team is a tight group of technologists and data scientists whose mission is to spread insight, information, and data driven solutions throughout the organization. We have complex data pipelines, large macroeconomic and market-based data sets, as well as our proprietary in-house data to develop with.\n\nRole Description\n\nWe are seeking a highly skilled and experienced Data Engineer to join our growing team. You will be responsible for designing, developing, and maintaining our data infrastructure and architecture. You will work closely with our data architect, data engineers and data analysts to ensure the availability and reliability of our data pipelines and systems. The ideal candidate has a strong background in data engineering and is passionate about leveraging data to drive business insights and decisions.\n\nPlease note that this job position entails in-person office requirements for a minimum of 3 days per week: Mondays, Tuesdays, and Wednesdays, located at Essex's corporate offices in Irvine, Woodland Hills, San Mateo, and Bellevue.\n\nResponsibilities\n• Design, build, and maintain scalable and high-performance data pipelines and infrastructure.\n• Collaborate with stakeholders to understand requirements and develop efficient data assets.\n• Implement data integration, transformation, and cleanse pipelines using industry best practices.\n• Design and implement data models and schemas to support business reporting and analytics.\n• Identifying and resolving performance bottlenecks and data quality issues.\n• Managing and monitoring data storage, backup, and recovery systems.\n• Performing data validation, testing, and ongoing data quality assurance.\n\nQualification And Work Experience Requirements\n• Bachelor's degree in computer science, engineering, or related field.\n• 2 - 5 years of demonstrable professional experience working as a Data Engineer.\n• Expert knowledge of data processing and transformation techniques.\n• In-depth understanding of data warehousing concepts and technologies.\n• Strong programming skills in Python and SQL.\n• Experience with cloud-based data platforms such as AWS, Google Cloud or Azure.\n• Proficiency in designing and implementing data models and schemas.\n• Knowledge of working with SSAS cubes using MDX and SSRS.\n• Familiarity with data integration and ETL tools such as Informatica, dbt, Matillion or Talend.\n• Practical knowledge of DevOps best practices.\n• Strong problem-solving skills and attention to detail.\n• Excellent communication and collaboration skills.\n• Ability to work effectively in a fast-paced and dynamic environment.\n• Effective communication and collaboration abilities.\n• Prior multi-family real estate experience a plus.\n• Good meme selection and desire to have fun.\n\nPreferred Experience\n• Experience building data models\n• Experience with Azure SQL or SQL Server\n• Experience with Snowflake\n• Experience with dbt\n• Experience with Matillion\n• Knowledge of Yardi\n\nAll full-time regular associates are offered competitive salaries, experience career growth, and are eligible for benefit packages that include medical, dental, vision, paid parental leave, 401k employer match, excellence rewards, wellness programs, and much more. With our Sunday property operations office closures, 10 paid holidays, and 15 PTO days, work/life balance is a priority! Additionally, most positions are eligible for a housing discount of 20%.\n\nEssex provides great communities in which to live, work and invest. We are a purpose-driven company, and we pride ourselves on promoting an internal culture of growth and opportunity by engaging, enabling, and empowering our teams. Working at Essex is not a destination. It is a journey where you can confidently build your career.\n\nThe salary range for this position is $101,000.00 - $151,000.00 per year. New hires generally start between $101,000.00 - $127,000.00 per year. The final salary offer will be determined after reviewing relevant factors, including but not limited to skill sets; relevant experience; internal equity; and other business and organizational needs.\n\nThis role is also eligible to participate in Essex’s discretionary Annual Bonus program that is commensurate with the level of the position.","job_is_remote":false,"job_posted_at_timestamp":1724149445,"job_posted_at_datetime_utc":"2024-08-20T10:24:05.000Z","job_city":"Laguna Niguel","job_state":"CA","job_country":"US","job_latitude":33.523674,"job_longitude":-117.71494,"job_benefits":["health_insurance","retirement_savings","paid_time_off","dental_coverage"],"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3DNYirA7P21JRzyE_OAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":"2024-09-19T10:24:04.000Z","job_offer_expiration_timestamp":1726741444,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"24","experience_mentioned":"true","experience_preferred":"true"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":"false","professional_certification":"false","high_school":"false","associates_degree":"false","bachelors_degree":"true","degree_mentioned":"true","degree_preferred":"true","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["The ideal candidate has a strong background in data engineering and is passionate about leveraging data to drive business insights and decisions","Bachelor's degree in computer science, engineering, or related field","2 - 5 years of demonstrable professional experience working as a Data Engineer","Expert knowledge of data processing and transformation techniques","In-depth understanding of data warehousing concepts and technologies","Strong programming skills in Python and SQL","Experience with cloud-based data platforms such as AWS, Google Cloud or Azure","Proficiency in designing and implementing data models and schemas","Knowledge of working with SSAS cubes using MDX and SSRS","Familiarity with data integration and ETL tools such as Informatica, dbt, Matillion or Talend","Practical knowledge of DevOps best practices","Strong problem-solving skills and attention to detail","Excellent communication and collaboration skills","Ability to work effectively in a fast-paced and dynamic environment","Effective communication and collaboration abilities","Good meme selection and desire to have fun"],"Responsibilities":["You will be responsible for designing, developing, and maintaining our data infrastructure and architecture","You will work closely with our data architect, data engineers and data analysts to ensure the availability and reliability of our data pipelines and systems","Design, build, and maintain scalable and high-performance data pipelines and infrastructure","Collaborate with stakeholders to understand requirements and develop efficient data assets","Implement data integration, transformation, and cleanse pipelines using industry best practices","Design and implement data models and schemas to support business reporting and analytics","Identifying and resolving performance bottlenecks and data quality issues","Managing and monitoring data storage, backup, and recovery systems","Performing data validation, testing, and ongoing data quality assurance"],"Benefits":["All full-time regular associates are offered competitive salaries, experience career growth, and are eligible for benefit packages that include medical, dental, vision, paid parental leave, 401k employer match, excellence rewards, wellness programs, and much more","With our Sunday property operations office closures, 10 paid holidays, and 15 PTO days, work/life balance is a priority!","The salary range for this position is $101,000.00 - $151,000.00 per year","New hires generally start between $101,000.00 - $127,000.00 per year","The final salary offer will be determined after reviewing relevant factors, including but not limited to skill sets; relevant experience; internal equity; and other business and organizational needs","This role is also eligible to participate in Essex’s discretionary Annual Bonus program that is commensurate with the level of the position"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":null,"job_naics_code":null,"job_naics_name":null},{"job_id":"0oAucT5b4364lKuBAAAAAA==","employer_name":"ClearanceJobs","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTDuCWzn1j4R6irCE2k3_HsOOY6moQvnk9pKDtT&s=0","employer_website":"http://www.clearancejobs.com","employer_company_type":null,"employer_linkedin":"https://www.crunchbase.com/organization/clearancejobs","job_publisher":"LinkedIn","job_employment_type":"FULLTIME","job_title":"Data Engineer - LONG TERM - Active TS/SCI Clearance with Security Clearance","job_apply_link":"https://www.linkedin.com/jobs/view/data-engineer-long-term-active-ts-sci-clearance-with-security-clearance-at-clearancejobs-4004990176?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.6281,"apply_options":[{"publisher":"LinkedIn","apply_link":"https://www.linkedin.com/jobs/view/data-engineer-long-term-active-ts-sci-clearance-with-security-clearance-at-clearancejobs-4004990176?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"Zachary Piper Solutions is currently seeking an innovative TS/SCI cleared Data Engineer to contribute to a major digital transformation initiative for the United States Space Force (USSF). The TS/SCI cleared Data Engineer will work on data mining projects, drawing valuable insights from multiple Department of Defense (DoD) repositories. This opportunity will be a long-term contract based in Los Angeles, CA, Albuquerque, NM, and Colorado Springs, CO though 100% on-site work. Responsibilities for the TS/SCI cleared Data Engineer Include:\n• Conduct methodical analytical experiments to solve complex problems and drive impactful change across diverse industries\n• Research cutting-edge data mining techniques and statistical models\n• Identify and collect relevant data sources to support client business needs, including large structured and unstructured datasets\n• Process, cleanse, and validate the integrity of data for analysis Qualifications for the TS/SCI cleared Data Engineer Include:\n• Bachelor's degree in Computer Science, Data Science, Data Analytics, Software Development, Information Technology, or a related discipline.\n• 5+ years of experience in data engineering.\n• Proficient in Python, SQL, R, and VBA.\n• Experience in building data visualizations, developing data pipelines, working with databases, data repositories and data management tools\n• Proficient in PowerBI\n• Active TS/SCI clearance Compensation for the TS/SCI cleared Data Engineer includes:\n• Salary Range: $150,000-$170,000/year depending on experience\n• Full Benefits: PTO, Medical, Dental, and Vision, 401K Keywords: data lake, delta lake, data mart, data warehouse, data Lakehouse, data mesh, data governance, data landscape, data analytics, data analytic, business analyst, internetofthings, internet of things, iot, rationalization, application rationalization, clinger-cohen, clingercohen, clinger-cohen act, cloud migration, Data analyst, powerbi, tableau, business objects, visualization, data analysis, power bi, data admin, data administrator, data administration, data task, data task lead, portfolio management, data integration, data management, data tools, data gathering, interface, system information, gap analysis, business case analysis, implementation plans, technology plans, analytics, dashboards, datamanagement, application rationalization, action officer, staffing, qlik, BOBJ, query, query development, data troubleshooting, interface, interface troubleshooting, ad-hoc, report creation, greenbelt, green belt, blackbelt, black belt, pmp, pmp certified, pmp certification, msoffice, microsoft, microsoft office, microsoftoffice, excel, powerpoint, ms project, ms access, usairforce, air force logistics, data scientist, data, data statistician, data architect, data engineer, Cleared, clearable, dod cleared, dod secret, dod clearance, secret clearance, ts, tssci, ts/sci, top secret clearance, top secret, secretclearance, secret, secret dod, dos secret, secret dos, top secret sci, top secret with sci, federally cleared, ts sci, active ts, active secret, active clearance, clearance active, sci eligible, sci eligibility, active top secret, dod clearance, active dod, active security, security clearance, veterans, reserve, reserves, reserve member, civilian, marine corp, marines, marine corps, active duty, retired military, military, army, navy, air force, us army, us navy, us air force, usmc, untied states service member, department of defense, dod, department of state, federal agency, federal contract, public sector, long term contracts, Permanent position, direct placement, direct hire, direct work, dp, Remote, remote work, remotework, hybrid, off-site, wfh, work from home, hybrid schedule, hybrid work, Air force, us air force, USAF, united states air force, washington dc, district, the district, d.c., washington d.c., virginia, dmv, maryland, dc maryland virginia, andrews afb, andrews air force base, andrews base, u.s. air force, air force logistics, business analyst, business task lead, air force installations, air force headquarters, usmc, united states marine corps, united states navy, veterans, officer, military, joint base, joing base andrews, pg county, prince george's county, maryland, camp springs air base, air force, andrews afb, afb, aafb, business analytics, military officer, HQ, headquarters, ms power bi, ms office power user, six sigma, sixsigma, 6sigma, office of management, budget exhibit, general officer, budget analyst, business analyst, budget compliance, budgeting compliance, acquisition, PPBE, dod, department of defense, dod agency, dod cleared, bachelors, bachelor's, degree, resource integration, migrating, migration, data migration, data systems, data ingestion, data acquisition, migration of data, facilitating, data facilitation, migration facilitation, cloud migration","job_is_remote":false,"job_posted_at_timestamp":1724285904,"job_posted_at_datetime_utc":"2024-08-22T00:18:24.000Z","job_city":"Los Angeles","job_state":"CA","job_country":"US","job_latitude":34.05491,"job_longitude":-118.242645,"job_benefits":["retirement_savings","paid_time_off"],"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3D0oAucT5b4364lKuBAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":"2024-09-21T00:18:24.000Z","job_offer_expiration_timestamp":1726877904,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"60","experience_mentioned":"true","experience_preferred":"false"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":"false","professional_certification":"false","high_school":"false","associates_degree":"false","bachelors_degree":"true","degree_mentioned":"true","degree_preferred":"true","professional_certification_mentioned":"true"},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15111100","job_onet_job_zone":"5","job_occupational_categories":null,"job_naics_code":null,"job_naics_name":null},{"job_id":"N44dwN1EsA9DKxeVAAAAAA==","employer_name":"Get It Recruit - Information Technology","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJqZ-ENXlzeEKmwDdcuUzh--MI4913tUgdUBZs&s=0","employer_website":null,"employer_company_type":null,"employer_linkedin":null,"job_publisher":"LinkedIn","job_employment_type":"FULLTIME","job_title":"Data Engineer, Senior - Remote | WFH","job_apply_link":"https://www.linkedin.com/jobs/view/data-engineer-senior-remote-wfh-at-get-it-recruit-information-technology-4004293422?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.6297,"apply_options":[{"publisher":"LinkedIn","apply_link":"https://www.linkedin.com/jobs/view/data-engineer-senior-remote-wfh-at-get-it-recruit-information-technology-4004293422?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Interlink Jobs","apply_link":"https://www.interlinkjobs.com/jobs/74473408-data-engineer-senior-remote-%7C-wfh?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"Job Title: Senior Data Engineer\n\nJob Category: Information Technology\n\nJob Level: Individual Contributor\n\nJob Type: Hybrid (Remote/On-site)\n\nLocation: Oakland, CA\n\nAbout Us\n\nOur Information Systems Technology Services team is a unified organization that brings together various departments to deliver high-quality technology solutions. We are committed to innovation, collaboration, and excellence in every project we undertake.\n\nPosition Overview\n\nWe are excited to welcome an experienced and talented Senior Data Engineer to our growing Data Analytics and Insights team. In this role, you'll be a crucial contributor to the design, development, and maintenance of data pipelines and analytic products, including data applications, reports, and dashboards.\n\nIf you're proactive, detail-oriented, and thrive in a fast-paced environment, this is the perfect opportunity for you to help us scale our analytic product development and meet the evolving needs of our clients. You'll collaborate with a cross-functional team, including solution architects, data pipeline engineers, data analysts, and data scientists, to ensure the optimal delivery of our analytic products.\n\nThis role offers a unique opportunity to be at the forefront of the utility industry, providing a comprehensive view of the nation's most advanced smart grid technology. It's an ideal position for someone looking to expand their professional experience while contributing to significant sustainability goals.\n\nWork Environment\n\nThis is a hybrid role, allowing you to work from your remote office and join us at our Oakland General Office once a month or for critical in-person meetings as needed.\n\nCompensation\n\nWe offer a competitive salary range based on the job's location and your unique qualifications. The actual salary will be determined by various factors, including your skills, education, certifications, experience, and market conditions. Additionally, this role is eligible for participation in our discretionary incentive compensation programs.\n\nSalary Range: $118,000 - $188,000 (Bay Area)\n\nKey Responsibilities\n\nCollaborate with Subject Matter Experts (SMEs) to design and develop data models, data pipelines, and front-end applications.\n\nImplement data transformations to create new datasets or ontology objects necessary for business applications.\n\nMonitor and resolve critical issues such as data staleness or quality concerns.\n\nEnhance the performance of data pipelines, focusing on reducing latency and optimizing resource usage.\n\nDevelop operational applications using tools like Workshop, Quiver, and Slate.\n\nCreate data visualizations with tools such as Quiver and Contour.\n\nMaintain and update applications as usage increases and requirements evolve.\n\nProvide 24/7 operational support as needed.\n\nMinimum Qualifications\n\nBachelor's degree in Computer Science, Engineering, or a related field.\n\n5+ years of experience as a data engineer or in a similar role.\n\nHands-on experience in building data pipelines from ingestion to final delivery.\n\nExperience in developing analytic applications, reports, or dashboards.\n\nProficiency in using no-code and low-code tools for analytic applications development.\n\nStrong SQL skills and experience with large datasets and complex data structures.\n\nProficiency in Python and/or PySpark.\n\nExperience With TypeScript (preferred) Or JavaScript.\n\nExcellent problem-solving and analytical skills with a keen attention to detail.\n\nExperience with the Palantir Foundry platform.\n\nPreferred Qualifications\n\nFamiliarity with commercial visualization tools like Tableau or Power BI.\n\nUnderstanding of relational database models and proprietary implementations, such as SAP, Salesforce, etc.\n\nKnowledge of Git for version control and collaboration workflows.\n\nExperience with Agile methodologies and iterative working processes.\n\nBasic knowledge of UX design best practices.\n\nData literacy, including data analysis and statistical basics for accurate data aggregation and visualization.\n\nWhy Join Us?\n\nThis role offers the chance to be part of an innovative and dynamic team where your contributions will make a meaningful impact. You'll work on cutting-edge projects and help advance key sustainability goals while continuing to build your career in a supportive and forward-thinking environment.\n\nEmployment Type: Full-Time","job_is_remote":true,"job_posted_at_timestamp":1724148018,"job_posted_at_datetime_utc":"2024-08-20T10:00:18.000Z","job_city":"Oakland","job_state":"CA","job_country":"US","job_latitude":37.80435,"job_longitude":-122.271164,"job_benefits":null,"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3DN44dwN1EsA9DKxeVAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":"2024-09-19T10:00:18.000Z","job_offer_expiration_timestamp":1726740018,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"60","experience_mentioned":"true","experience_preferred":"true"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":"false","professional_certification":"false","high_school":"false","associates_degree":"false","bachelors_degree":"true","degree_mentioned":"true","degree_preferred":"true","professional_certification_mentioned":"true"},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Bachelor's degree in Computer Science, Engineering, or a related field","5+ years of experience as a data engineer or in a similar role","Hands-on experience in building data pipelines from ingestion to final delivery","Experience in developing analytic applications, reports, or dashboards","Proficiency in using no-code and low-code tools for analytic applications development","Strong SQL skills and experience with large datasets and complex data structures","Proficiency in Python and/or PySpark","Excellent problem-solving and analytical skills with a keen attention to detail","Experience with the Palantir Foundry platform","Familiarity with commercial visualization tools like Tableau or Power BI","Understanding of relational database models and proprietary implementations, such as SAP, Salesforce, etc","Knowledge of Git for version control and collaboration workflows","Experience with Agile methodologies and iterative working processes","Basic knowledge of UX design best practices","Data literacy, including data analysis and statistical basics for accurate data aggregation and visualization"],"Responsibilities":["In this role, you'll be a crucial contributor to the design, development, and maintenance of data pipelines and analytic products, including data applications, reports, and dashboards","If you're proactive, detail-oriented, and thrive in a fast-paced environment, this is the perfect opportunity for you to help us scale our analytic product development and meet the evolving needs of our clients","You'll collaborate with a cross-functional team, including solution architects, data pipeline engineers, data analysts, and data scientists, to ensure the optimal delivery of our analytic products","Collaborate with Subject Matter Experts (SMEs) to design and develop data models, data pipelines, and front-end applications","Implement data transformations to create new datasets or ontology objects necessary for business applications","Monitor and resolve critical issues such as data staleness or quality concerns","Enhance the performance of data pipelines, focusing on reducing latency and optimizing resource usage","Develop operational applications using tools like Workshop, Quiver, and Slate","Create data visualizations with tools such as Quiver and Contour","Maintain and update applications as usage increases and requirements evolve","Provide 24/7 operational support as needed"],"Benefits":["This is a hybrid role, allowing you to work from your remote office and join us at our Oakland General Office once a month or for critical in-person meetings as needed","We offer a competitive salary range based on the job's location and your unique qualifications","The actual salary will be determined by various factors, including your skills, education, certifications, experience, and market conditions","Additionally, this role is eligible for participation in our discretionary incentive compensation programs","Salary Range: $118,000 - $188,000 (Bay Area)","You'll work on cutting-edge projects and help advance key sustainability goals while continuing to build your career in a supportive and forward-thinking environment"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":null,"job_naics_code":null,"job_naics_name":null},{"job_id":"BrhM1zFpC1vkddqhAAAAAA==","employer_name":"Abbott Laboratories","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ4F4BqX_1FV8BDQlePPc8fnqxjFPO2We9By3gi&s=0","employer_website":"http://www.abbott.com","employer_company_type":null,"employer_linkedin":"https://en.m.wikipedia.org/wiki/File:Abbott_Laboratories_logo.svg","job_publisher":"Abbott Jobs","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https://www.jobs.abbott/us/en/job/31082856/Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.8067,"apply_options":[{"publisher":"Abbott Jobs","apply_link":"https://www.jobs.abbott/us/en/job/31082856/Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Experteer","apply_link":"https://www.experteer.fr/account/signup_now/job/46849464?signup_link=lo_job_title&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"BeBee","apply_link":"https://us.bebee.com/job/97bf26dcf88f789bb5b3a43c002d2840?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Experteer","apply_link":"https://www.experteer.es/account/signup_now/job/46849464?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Talent.com","apply_link":"https://www.talent.com/view?id=ce838920a8c0&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"DataYoshi","apply_link":"https://datayoshi.com/offer/567067/data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"H-1B Job Board - Ellis","apply_link":"https://h1bjobs.ellis.com/companies/abbott/jobs/35576967-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"JobsMarket","apply_link":"https://us.jobsmarket.io/jobs/view/data-engineer-199920.html?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 114,000 colleagues serve people in more than 160 countries.\n\nData Engineer\n\nAbout Lingo\n\nMeet Lingo, a new biosensing technology that provides users a window into their body. Lingo tracks key biomarkers – such as glucose, ketones, and lactate – to help people make better decisions about their health and nutrition. Biowearable technology will digitize, decentralize and democratize healthcare, enabling consumers to take control of their own health.\n\nWorking at Abbott\n\nAt Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:\n• Career development with an international company where you can grow the career you dream of .\n• Free medical coverage for employees* via the Health Investment Plan (HIP) PPO\n• An excellent retirement savings plan with high employer contribution\n• Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.\n• A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.\n• A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.\n\nThe opportunity\n\nPersonalized healthcare is the future. Working on Lingo, you will help build a next-generation technology that enables individuals to make decisions about how to improve energy, lose weight or enhance athletic performance. The Lingo team embodies a start-up culture and mindset with the backing of Abbott, a company with a rich history of healthcare innovation. Join us and grow your career as you help Abbott shape the future of healthcare.\n\nThis position works out of our <> location in Lingo.\n\nYou will work closely with a multidisciplinary agile team to build high-quality data pipelines for high-end analytics solutions. These solutions will generate insights from the organization’s connected data and enable data-driven decision-making capabilities for the organization.\n\nWhat you’ll do\n• Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals\n• Solve complex data problems to deliver insights that help the organization achieve its goals\n• Code in Python and Scala with tools like Apache Spark/Kafka to build a multi-cluster data warehouse\n• Interact with other technology teams to define, prioritize, and ensure smooth deployments for other operational components\n• Advise, consult, mentor, and coach other data and analytics professionals on data standards and practices\n• Foster a culture of sharing, reuse, design for scale stability, and operational efficiency of data and analytical solutions\n• Codify best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate data capturing and management\n\nQualifications\n• 4+ years of relevant experience in data engineering/analytics space\n• Expertise in SQL and data analysis and strong hands-on expertise with at least one programming language: Python and/or Scala\n• Strong knowledge in one or more of the following big data tools: Hive, Hadoop Impala, Spark, Kafka\n• Strong expertise in ETL, reporting tools, data governance, data warehousing, and hands-on experience\n• Experience developing solutions for cloud computing services and infrastructure\n• Experience developing and maintaining data warehouses in big data solutions\n• Up-to-date on industry trends within the analytics space from a data acquisition processing, engineering, and management perspective\n• Experience in agile development\n• Strong people skills, specifically in collaboration and teamwork\n• High level of curiosity, creativity, and problem-solving capabilities\n\nWHAT WE OFFER\n\nAt Abbott, you can have a good job that can grow into a great career. We offer:\n• Training and career development, with onboarding programs for new employees and tuition assistance\n• Financial security through competitive compensation, incentives and retirement plans\n• Health care and well-being programs including medical, dental, vision, wellness and occupational health programs\n• Paid time off\n• 401(k) retirement savings with a generous company match\n• The stability of a company with a record of strong financial performance and history of being actively involved in local communities\n\nLearn more about our benefits that add real value to your life to help you live fully: http://www.abbottbenefits.com/pages/candidate.aspx\n\nFollow your career aspirations to Abbott for diverse opportunities with a company that provides the growth and strength to build your future. Abbott is an Equal Opportunity Employer, committed to employee diversity. Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.\n\nThe base pay for this position is $95,500.00 – $190,900.00. In specific locations, the pay range may vary from the range posted.","job_is_remote":false,"job_posted_at_timestamp":1723852800,"job_posted_at_datetime_utc":"2024-08-17T00:00:00.000Z","job_city":"Alameda","job_state":"CA","job_country":"US","job_latitude":37.779873,"job_longitude":-122.28219,"job_benefits":["dental_coverage","health_insurance","retirement_savings","paid_time_off"],"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3DBrhM1zFpC1vkddqhAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"48","experience_mentioned":"true","experience_preferred":"false"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":"true","degree_preferred":"false","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["4+ years of relevant experience in data engineering/analytics space","Expertise in SQL and data analysis and strong hands-on expertise with at least one programming language: Python and/or Scala","Strong knowledge in one or more of the following big data tools: Hive, Hadoop Impala, Spark, Kafka","Strong expertise in ETL, reporting tools, data governance, data warehousing, and hands-on experience","Experience developing solutions for cloud computing services and infrastructure","Experience developing and maintaining data warehouses in big data solutions","Up-to-date on industry trends within the analytics space from a data acquisition processing, engineering, and management perspective","Experience in agile development","Strong people skills, specifically in collaboration and teamwork","High level of curiosity, creativity, and problem-solving capabilities"],"Responsibilities":["You will work closely with a multidisciplinary agile team to build high-quality data pipelines for high-end analytics solutions","These solutions will generate insights from the organization’s connected data and enable data-driven decision-making capabilities for the organization","Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals","Solve complex data problems to deliver insights that help the organization achieve its goals","Code in Python and Scala with tools like Apache Spark/Kafka to build a multi-cluster data warehouse","Interact with other technology teams to define, prioritize, and ensure smooth deployments for other operational components","Advise, consult, mentor, and coach other data and analytics professionals on data standards and practices","Foster a culture of sharing, reuse, design for scale stability, and operational efficiency of data and analytical solutions","Codify best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate data capturing and management"],"Benefits":["Career development with an international company where you can grow the career you dream of ","Free medical coverage for employees* via the Health Investment Plan (HIP) PPO","An excellent retirement savings plan with high employer contribution","Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree","Training and career development, with onboarding programs for new employees and tuition assistance","Financial security through competitive compensation, incentives and retirement plans","Health care and well-being programs including medical, dental, vision, wellness and occupational health programs","Paid time off","401(k) retirement savings with a generous company match","The stability of a company with a record of strong financial performance and history of being actively involved in local communities","The base pay for this position is $95,500.00 – $190,900.00","In specific locations, the pay range may vary from the range posted"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":["Research & Development"],"job_naics_code":"325412","job_naics_name":"Pharmaceutical Preparation Manufacturing"},{"job_id":"9Iq813xp8gFV9LWZAAAAAA==","employer_name":"CyberCoders","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTIO7Tj3XxjHkqt4kmmscpzSOBJtP1UZPkdey18&s=0","employer_website":"http://www.cybercoders.com","employer_company_type":null,"employer_linkedin":"https://www.cybercoders.com/insights/press-release-cybercoders-is-acquired-by-on-assignment-for-105-million/","job_publisher":"LinkedIn","job_employment_type":"FULLTIME","job_title":"CA Data Engineer, Data Acquisition, AWS, Python, Big Data","job_apply_link":"https://www.linkedin.com/jobs/view/ca-data-engineer-data-acquisition-aws-python-big-data-at-cybercoders-4005505578?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.626,"apply_options":[{"publisher":"LinkedIn","apply_link":"https://www.linkedin.com/jobs/view/ca-data-engineer-data-acquisition-aws-python-big-data-at-cybercoders-4005505578?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Indeed","apply_link":"https://www.indeed.com/viewjob?jk=f5e580a4e551103b&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"SimplyHired","apply_link":"https://www.simplyhired.com/job/CmeGux-4fDAPIb8pTANxqcQZDAodCijtL-JqnwRMX0b70OBZH-WgOg?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Jooble","apply_link":"https://jooble.org/jdp/3878512476485654429?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"Data Engineer\n\nPosition Overview\n\nAs a data engineer, you will be responsible for designing, building, and maintaining the data architecture for our company. You will work closely with the data science and business intelligence teams to ensure that our data is accurate, accessible, and secure.\n\nKey Responsibilities\n• Design and implement data acquisition and integration solutions to support business needs\n• Create and maintain scalable and efficient data pipelines\n• Collaborate with data science and business intelligence teams to ensure data accuracy and accessibility\n• Perform data modeling, database design, and optimization\n• Research and evaluate new technologies and tools to improve data architecture and infrastructure\n\nQualifications\n• Bachelor's degree in Computer Science, Information Technology or related field\n• Minimum of 3 years of experience as a data engineer\n• Experience with data acquisition and integration\n• Experience with big data technologies such as Hadoop, Databricks, and Spark\n• Experience with cloud-based solutions such as Azure Synapse and Data Factory\n• Proficiency in programming languages such as Python, Java, and C++\n• Experience with message queue and stream processing\n• Strong analytical skills and attention to detail\n\nBenefits\n\nLooking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:\n\nEmail Your Resume In Word To\n\nruss.holland@cybercoders.com\n• Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : RH-1815963 -- in the email subject line for your application to be considered.***\n\nRuss Holland - Principal Recruiter\n\nApplicants must be authorized to work in the U.S.\n\nCyberCoders is proud to be an Equal Opportunity Employer\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity or expression, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, status as a crime victim, disability, protected veteran status, or any other characteristic protected by law. CyberCoders will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. CyberCoders is committed to working with and providing reasonable accommodation to individuals with physical and mental disabilities. If you need special assistance or an accommodation while seeking employment, please contact a member of our Human Resources team to make arrangements.","job_is_remote":false,"job_posted_at_timestamp":1724125810,"job_posted_at_datetime_utc":"2024-08-20T03:50:10.000Z","job_city":"Fresno","job_state":"CA","job_country":"US","job_latitude":36.737797,"job_longitude":-119.787125,"job_benefits":null,"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3D9Iq813xp8gFV9LWZAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":"2024-09-19T03:50:10.000Z","job_offer_expiration_timestamp":1726717810,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"36","experience_mentioned":"true","experience_preferred":"false"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":"false","professional_certification":"false","high_school":"false","associates_degree":"false","bachelors_degree":"true","degree_mentioned":"true","degree_preferred":"true","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":75000,"job_max_salary":110000,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Bachelor's degree in Computer Science, Information Technology or related field","Minimum of 3 years of experience as a data engineer","Experience with data acquisition and integration","Experience with big data technologies such as Hadoop, Databricks, and Spark","Experience with cloud-based solutions such as Azure Synapse and Data Factory","Proficiency in programming languages such as Python, Java, and C++","Experience with message queue and stream processing","Strong analytical skills and attention to detail","Applicants must be authorized to work in the U.S"],"Responsibilities":["As a data engineer, you will be responsible for designing, building, and maintaining the data architecture for our company","You will work closely with the data science and business intelligence teams to ensure that our data is accurate, accessible, and secure","Design and implement data acquisition and integration solutions to support business needs","Create and maintain scalable and efficient data pipelines","Perform data modeling, database design, and optimization","Research and evaluate new technologies and tools to improve data architecture and infrastructure"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":null,"job_naics_code":null,"job_naics_name":null},{"job_id":"o_LDKJOF_YXJB0lKAAAAAA==","employer_name":"LeafLink","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRdFj6QRcQgur3i9udZ_U7Pju_5yiZsthj7DCTR&s=0","employer_website":"http://www.leaflink.com","employer_company_type":null,"employer_linkedin":"https://mjbizcon.app.swapcard.com/event/mjbizcon/exhibitor/RXhoaWJpdG9yXzIxNTUyNw==","job_publisher":"Adzuna","job_employment_type":"FULLTIME","job_title":"Principal Data Engineer, Platform","job_apply_link":"https://www.adzuna.com/details/4831460793?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.4962,"apply_options":[{"publisher":"Adzuna","apply_link":"https://www.adzuna.com/details/4831460793?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"JoPilot","apply_link":"https://jobs.jopilot.net/job/0GPGcpEBNDRfCFvuLxY_0824?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"LeafLink is the largest unified B2B cannabis platform, providing licensed cannabis businesses a suite of tools to manage their business more effectively, sell or order from their favorite brands and accelerate growth. We are one platform, one solution and we’re defining the way thousands of cannabis brands, distributors, and retailers streamline their operations. With thousands of brands and retailers across 30+ markets in North America, we are setting the industry standard for how cannabis businesses grow together. LeafLink processes more than $5 billion in wholesale cannabis orders annually.\n\nOur team, backed by funding from leading VCs, including Founders Fund, Thrive Capital, Nosara Capital, and Lerer Hippeau is poised to define the cannabis supply chain through technology. LeafLink was named one of Inc. 5000’s ‘Top 5000 Fastest-Growing Private Companies’, one of Built In NYCs Best Places to Work in 2021, as well as one of Fast Companys Top 10 Most Innovative Companies in Enterprise for 2020, joining the ranks of Amazon, Slack, and VMWare - and were just getting started!\n\nThe Role\n\nLeafLink is seeking a Principal Data Engineer to join our remote-friendly team, headquartered in NYC, who is passionate about working with teams that solve interesting, large-scale problems rapidly. This impactful position enables LeafLink to coordinate and integrate with 3rd party data sets and proprietary data to produce valuable insights into business and customer needs. As a member of our engineering team, you will be in a position to have a direct and lasting impact everywhere in the company. Your contribution will be immediate and have positive ripple effects across not just our business, but also the business of each of our customers.\n\nLeafLink is currently tackling a large-scale platform overhaul that will strengthen our position as a technical leader within the industry. As such, this role has the opportunity to help lead, shape, and grow the data and machine learning architecture within our platform, as well as work with new and growing technologies. It’s a very exciting time to join our engineering team!\n\nIdeal candidates for this position should possess a keen mind for solving tough problems with the ideal solution, partnering effectively with various team members along the way. They should be deeply passionate about organizing and managing data at scale for various use cases. They should be personable, efficient, flexible, and communicative, have a strong desire to implement change, grow, mature, and have a passion and love for their work. This role comes with the opportunity to be a high performer within a fast-paced, dynamic, and quickly growing department in all areas.\n\nWhat You’ll Be Doing\n\n• Audit, design, and maintain a high-performing, modular, and optimal data pipeline architecture for structured and unstructured use cases around machine learning, reporting, and analytics\n\n• Design and co-build with Cloud and DevOps the infrastructure and operations required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, python, and AWS cloud technologies\n\n• Keep up to date on modern technologies and trends and advocate for their inclusion within products when it makes sense\n\n• Analyze and evaluate existing solutions and make decisions on whether to extend or refactor as needed with a major focus on improving our pipeline and reporting performance\n\n• Work with the CTO and department stakeholders to properly plan short and long-term goals, and define and execute a technical roadmap that continues to evolve LeafLink’s data capabilities and functionality to meet the needs of our Business and Product Vision.\n\n• Work collaboratively with multiple cross-functional agile teams to help deliver end-to-end products and features enabled by our data pipeline, seeing them through from conception to delivery\n\n• Help define, document, evolve, and evangelize high engineering standards, best practices, tenants, and data management & governance across data and analytics engineering\n\n• Move quickly and intelligently - seeing technical debt as your nemesis and eliminating risk\n\n• Effectively communicate the complexity of your work to technical and non-technical audiences through non-written and written mediums\n\n• Design, develop, and test data models in our data warehouse that enable data and analytics processes\n\n• Help define and build our enterprise data catalog and dictionary\n\n• Troubleshoot, diagnose and address data quality issues quickly and effectively while implementing solutions to combat this at scale, including improved quality controls and observability and monitoring\n\n• Provide mentorship and growth to our BE and Data engineers while creating repeatable and scalable solutions and patterns\n\nWhat You’ll Bring to the Team\n\n• Minimum of 10 years experience in a professional working environment on a data or engineering team\n\n• Individual contributor leadership to our data and analytics engineers and specialization on our current Platform Engineering team around data enterprise architecture and best practices\n\n• Advanced working SQL knowledge and experience working with relational and non-relational databases, query authoring (SQL) as well as working familiarity with a variety of data stores\n\n• Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\n\n• Expertise writing Python processing jobs to ingest a variety of structured and unstructured data received from various sources & formats such as Rest APIs, Flat Files, and Logs with the ability to support and scale to both smaller and larger dataset ingestions\n\n• They should also have experience using the following software/tools:\n\n• Comfortable working in a fast-paced growth business with many collaborators and quickly evolving business needs\n\n• Consistency and standards to how we visualize and use our enterprise data at LeafLink through helping us define our first Data Dictionary and Catalog\n\nLeafLink Perks & Benefits\n\n• Flexible PTO - you’re going to be working hard so enjoy time off with no cap!\n\n• A robust stock option plan to give our employees a direct stake in LeafLink’s success\n\n• 5 Days of Volunteer Time Off (VTO) - giving back is important to us and we want our employees to prioritize cultivating a better community\n\n• Competitive compensation and 401k match\n\n• Comprehensive health coverage (medical, dental, vision)\n\n• Commuter Benefits through our Flexible Spending Account","job_is_remote":false,"job_posted_at_timestamp":1724025600,"job_posted_at_datetime_utc":"2024-08-19T00:00:00.000Z","job_city":"Campbell","job_state":"CA","job_country":"US","job_latitude":37.287167,"job_longitude":-121.94996,"job_benefits":["retirement_savings","paid_time_off","health_insurance","dental_coverage"],"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3Do_LDKJOF_YXJB0lKAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":"2024-09-02T17:02:57.000Z","job_offer_expiration_timestamp":1725296577,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"120","experience_mentioned":"true","experience_preferred":"false"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":"false","degree_preferred":"false","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Ideal candidates for this position should possess a keen mind for solving tough problems with the ideal solution, partnering effectively with various team members along the way","They should be deeply passionate about organizing and managing data at scale for various use cases","They should be personable, efficient, flexible, and communicative, have a strong desire to implement change, grow, mature, and have a passion and love for their work","Minimum of 10 years experience in a professional working environment on a data or engineering team","Individual contributor leadership to our data and analytics engineers and specialization on our current Platform Engineering team around data enterprise architecture and best practices","Advanced working SQL knowledge and experience working with relational and non-relational databases, query authoring (SQL) as well as working familiarity with a variety of data stores","Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement","Expertise writing Python processing jobs to ingest a variety of structured and unstructured data received from various sources & formats such as Rest APIs, Flat Files, and Logs with the ability to support and scale to both smaller and larger dataset ingestions","They should also have experience using the following software/tools:","Comfortable working in a fast-paced growth business with many collaborators and quickly evolving business needs","Consistency and standards to how we visualize and use our enterprise data at LeafLink through helping us define our first Data Dictionary and Catalog"],"Responsibilities":["Audit, design, and maintain a high-performing, modular, and optimal data pipeline architecture for structured and unstructured use cases around machine learning, reporting, and analytics","Design and co-build with Cloud and DevOps the infrastructure and operations required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, python, and AWS cloud technologies","Keep up to date on modern technologies and trends and advocate for their inclusion within products when it makes sense","Analyze and evaluate existing solutions and make decisions on whether to extend or refactor as needed with a major focus on improving our pipeline and reporting performance","Work with the CTO and department stakeholders to properly plan short and long-term goals, and define and execute a technical roadmap that continues to evolve LeafLink’s data capabilities and functionality to meet the needs of our Business and Product Vision","Work collaboratively with multiple cross-functional agile teams to help deliver end-to-end products and features enabled by our data pipeline, seeing them through from conception to delivery","Help define, document, evolve, and evangelize high engineering standards, best practices, tenants, and data management & governance across data and analytics engineering","Move quickly and intelligently - seeing technical debt as your nemesis and eliminating risk","Effectively communicate the complexity of your work to technical and non-technical audiences through non-written and written mediums","Design, develop, and test data models in our data warehouse that enable data and analytics processes","Help define and build our enterprise data catalog and dictionary","Troubleshoot, diagnose and address data quality issues quickly and effectively while implementing solutions to combat this at scale, including improved quality controls and observability and monitoring","Provide mentorship and growth to our BE and Data engineers while creating repeatable and scalable solutions and patterns"],"Benefits":["LeafLink Perks & Benefits","Flexible PTO - you’re going to be working hard so enjoy time off with no cap!","A robust stock option plan to give our employees a direct stake in LeafLink’s success","5 Days of Volunteer Time Off (VTO) - giving back is important to us and we want our employees to prioritize cultivating a better community","Competitive compensation and 401k match","Comprehensive health coverage (medical, dental, vision)","Commuter Benefits through our Flexible Spending Account"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":null,"job_naics_code":null,"job_naics_name":null},{"job_id":"tizXCs06dIpXSI34AAAAAA==","employer_name":"TEKsystems","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRnXsEN7UUtvSpIi0itdBndnljUWnfdCSoQtMsq&s=0","employer_website":"http://www.teksystems.com","employer_company_type":null,"employer_linkedin":"https://www.teksystems.com/","job_publisher":"TEKsystems Careers","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https://careers.teksystems.com/us/en/job/JP-004468978/Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.9102,"apply_options":[{"publisher":"TEKsystems Careers","apply_link":"https://careers.teksystems.com/us/en/job/JP-004468978/Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Indeed","apply_link":"https://www.indeed.com/viewjob?jk=88cc7d1f5293dc3a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Glassdoor","apply_link":"https://www.glassdoor.com/job-listing/data-engineer-duopeak-JV_IC1147371_KO0,13_KE14,21.htm?jl=1006766528974&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"LinkedIn","apply_link":"https://www.linkedin.com/jobs/view/enterprise-engineer-at-dice-4004363040?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"ZipRecruiter","apply_link":"https://www.ziprecruiter.com/c/InterSources/Job/Data-Engineer/-in-Menlo-Park,CA?jid=5d4943a1b023341c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Rise","apply_link":"https://app.joinrise.co/jobs/data-engineer-05g1?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Meta Careers","apply_link":"https://www.metacareers.com/jobs/1059432802208498/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Dice","apply_link":"https://www.dice.com/job-detail/877f0319-9afb-4cf5-8721-c3c652421dfd?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"Summary:\n\nThe main function of the Data Engineer is to develop evaluate test and maintain architectures and data solutions within our organization. The typical Data Engineer executes plans policies and practices that control protect deliver and enhance the value of the organizations data assets.\n\nJob Responsibilities:\n\n• SQL\n\n• Python\n\n• ETL and data pipeline experience\n\nJob Responsibilities:\n\n• Design construct install test and maintain highly scalable data management systems.\n\n• Ensure systems meet business requirements and industry practices.\n\n• Design implement automate and maintain large scale enterprise data ETL processes.\n\n• Build high-performance algorithms prototypes predictive models and proof of concepts.\n\nSkills:\n\n• Ability to work as part of a team as well as work independently or with minimal direction.\n\n• Excellent written presentation and verbal communication skills.\n\n• Collaborate with data architects modelers and IT team members on project goals.\n\nEducation/Experience:\n\n• Bachelor's degree in a technical field such as computer science computer engineering or related field required.\n\nAbout TEKsystems:\n\nWe're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.\n\nThe company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.","job_is_remote":false,"job_posted_at_timestamp":1723766400,"job_posted_at_datetime_utc":"2024-08-16T00:00:00.000Z","job_city":"Menlo Park","job_state":"CA","job_country":"US","job_latitude":37.45296,"job_longitude":-122.181725,"job_benefits":null,"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3DtizXCs06dIpXSI34AAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":null,"experience_mentioned":"true","experience_preferred":"false"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":"true","degree_preferred":"true","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":65,"job_max_salary":100,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Python","Ability to work as part of a team as well as work independently or with minimal direction","Excellent written presentation and verbal communication skills","Collaborate with data architects modelers and IT team members on project goals","Bachelor's degree in a technical field such as computer science computer engineering or related field required"],"Responsibilities":["The main function of the Data Engineer is to develop evaluate test and maintain architectures and data solutions within our organization","The typical Data Engineer executes plans policies and practices that control protect deliver and enhance the value of the organizations data assets","SQL","Design construct install test and maintain highly scalable data management systems","Ensure systems meet business requirements and industry practices","Design implement automate and maintain large scale enterprise data ETL processes","Build high-performance algorithms prototypes predictive models and proof of concepts"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":["Other"],"job_naics_code":"561311","job_naics_name":"Employment Placement Agencies"},{"job_id":"XKY0dAhrC8LdCUUiAAAAAA==","employer_name":"BlackLine","employer_logo":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTijiONPdK1_t7is97g8SgObbpAnWbyNNkKORIO&s=0","employer_website":"http://www.blackline.com","employer_company_type":null,"employer_linkedin":"https://www.prnewswire.com/news-releases/blackline-makes-software-500-list-for-7th-year-in-a-row-300565431.html","job_publisher":"BlackLine Careers","job_employment_type":"FULLTIME","job_title":"Staff Data Engineer","job_apply_link":"https://careers.blackline.com/careers-home/jobs/4688?lang=en-us&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":true,"job_apply_quality_score":0.9031,"apply_options":[{"publisher":"BlackLine Careers","apply_link":"https://careers.blackline.com/careers-home/jobs/4688?lang=en-us&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":true},{"publisher":"LinkedIn","apply_link":"https://www.linkedin.com/jobs/view/staff-data-engineer-at-blackline-3958445551?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"The Muse","apply_link":"https://www.themuse.com/jobs/blackline/staff-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":true},{"publisher":"Built In Los Angeles","apply_link":"https://www.builtinla.com/job/staff-data-engineer/166550?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Talent.com","apply_link":"https://www.talent.com/view?id=66560b645896&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Monster","apply_link":"https://www.monster.com/job-openings/staff-data-engineer-los-angeles-ca--c43bc136-55ba-4918-bf52-915fd56181f7?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Ladders","apply_link":"https://www.theladders.com/job/staff-data-engineer-blackline-los-angeles-ca_73313597?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"BeBee","apply_link":"https://us.bebee.com/job/a16c7d5983282e613a9267cb1f849be0?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"Get to Know Us:\n\nIt's fun to work in a company where people truly believe in what they're doing! At BlackLine, we're committed to bringing passion and customer focus to the business of enterprise applications.\n\nSince being founded in 2001, BlackLine has become a leading provider of cloud software that automates and controls the entire financial close process. Our vision is to modernize the finance and accounting function to enable greater operational effectiveness and agility, and we are committed to delivering innovative solutions and services to empower accounting and finance leaders around the world to achieve Modern Finance.\n\nBeing a best-in-class SaaS Company, we understand that bringing in new ideas and innovative technology is mission critical. At BlackLine we are always working with new, cutting edge technology that encourages our teams to learn something new and expand their creativity and technical skillset that will accelerate their careers.\n\nWork, Play and Grow at BlackLine!\n\nMake Your Mark:\n\nAs a member of the Data & BI Engineering team you will primarily focus on advancing our Enterprise Data Platform to allow the organization to make data-driven decisions. The successful candidate will work closely with cross-functional teams to identify business requirements, design, and develop data models, data warehouses, and data visualization solutions that help support the organization's strategic goals.\n\nThe Staff Data Engineer will work in a dynamic environment and will be required to stay current with the latest trends and technologies in the business intelligence field. The ideal candidate will be able to pick up business domain and internal process knowledge and leverage that knowledge to think strategically, communicate effectively, and manage multiple projects simultaneously.\n\nThe team is also responsible for administering tools and platforms around reporting, analytics, and data visualization while promoting best practices. The role requires a strong combination of technical expertise, leadership skills, and a deep understanding of data engineering principles and best practices. We are looking for a driven, detail-oriented, and passionate engineer to come to join our team.\n\nYou'll Get To:\n• Design and build infrastructure for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources, including data identification, mapping, aggregation, conditioning, cleansing, and analyzing.\n• Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n• Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand data requirements and deliver valuable insights.\n• Effectively communicate complex technical concepts to non-technical audiences.\n• Maintain documentation and operational knowledge base.\n• Coach and technically train junior staff on design and development standards and best practices.\n• Design and implement data security and governance protocols to ensure the accuracy and reliability of data.\n\nWhat You'll Bring:\n• Bachelor's or Master's degree in Computer Science, Data Science, or a related field.\n• 10+ years as a data engineer.\n• 10+ years of experience using RDBMS, SQL, Python, Java, or other programming languages is a plus.\n• 5+ years working experience with SQL and familiarity with Snowflake data warehouse, strong working knowledge in stored procedures, CTEs, and UDFs, RBAC.\n• Deep understanding of Data warehouse concepts, star, snowflake and dimensional modeling modeling and ETL/ELT best practices, scalability, complex process management, self-healing approaches, etc.\n• Strong working knowledge in at-least one of the big data architecture such as Lambda, Kappa and Hub and Spoke Architectures.\n• Excellent proficiency in Stream-processing systems like Storm, Spark-Streaming, kafka streaming and building real time data pipelines.\n• Proficiency in Container technologies: Docker, and Kubernetes.\n• Experience with modern Data Replication and Data processing tools such as Qlik, Fivetran.\n• Understanding of data security and privacy regulations, with experience implementing data security best practices.\n• Ability to define and manage user roles and permissions in Snowflake to ensure data security and privacy.\n• Experience in working in a startup-type environment, good team player, and can work independently with minimal supervision.\n• Proficient in managing large volumes of data.\n• Strong analytical and interpersonal skills, comfortable presenting complex ideas in simple terms.\n• Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams.\n• Experience in providing technical support and troubleshooting for data-related issues.\n\nWe’re Even More Excited If You Have:\n• Experience with nosql systems such as mongodb, cockroachDb, apache cassandra etc.\n• Experience with cloud platforms such as AWS, Azure, or Google Cloud is a plus.\n• Significant experience with open source platforms and technologies.\n• Experience with data science and machine learning tools and technologies is a plus.\n\nThrive at BlackLine Because You Are Joining:\n• A technology-based company with a sense of adventure and a vision for the future. Every door at BlackLine is open. Just bring your brains, your problem-solving skills, and be part of a winning team at the world's most trusted name in Finance Automation!\n• A culture that is kind, open, and accepting. It's a place where people can embrace what makes them unique, and the mix of cultural backgrounds and varying interests cultivates diverse thought and perspectives.\n• A culture where BlackLiner's continued growth and learning is empowered. BlackLine offers a wide variety of professional development seminars and inclusive affinity groups to celebrate and support our diversity.\n\nBlackLine is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity or expression, race, age, religious creed, national origin, physical or mental disability, ancestry, color, marital status, sexual orientation, military or veteran status, status as a victim of domestic violence, sexual assault or stalking, medical condition, genetic information, or any other protected class or category recognized by applicable equal employment opportunity or other similar laws.\n\nBlackLine recognizes that the ways we work and the workplace itself has shifted. We innovate in a workplace that optimizes a combination of virtual and in-person interactions to maximize collaboration and nurture our culture. Candidates who live within a reasonable commute to one of our offices will work in the office at least 2 days a week.\n\nSalary Range:\n\nUSD $147,000.00 - USD $196,000.00\n\nPay Transparency Statement:\n\nPlacement within this range depends upon several factors, including the applicant's prior relevant job experience, skill set, and geographic location. In addition to base pay, BlackLine also offers short-term and long-term incentive programs, based on eligibility, along with a robust offering of benefit and wellness plans.","job_is_remote":false,"job_posted_at_timestamp":1719242760,"job_posted_at_datetime_utc":"2024-06-24T15:26:00.000Z","job_city":"Los Angeles","job_state":"CA","job_country":"US","job_latitude":34.05491,"job_longitude":-118.242645,"job_benefits":["health_insurance"],"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3DXKY0dAhrC8LdCUUiAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":"2025-06-24T15:26:19.000Z","job_offer_expiration_timestamp":1750778779,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"120","experience_mentioned":"true","experience_preferred":"true"},"job_required_skills":["UNAVAILABLE"],"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":"true","degree_preferred":"true","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":0,"job_max_salary":0,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["The role requires a strong combination of technical expertise, leadership skills, and a deep understanding of data engineering principles and best practices","Bachelor's or Master's degree in Computer Science, Data Science, or a related field","10+ years as a data engineer","5+ years working experience with SQL and familiarity with Snowflake data warehouse, strong working knowledge in stored procedures, CTEs, and UDFs, RBAC","Deep understanding of Data warehouse concepts, star, snowflake and dimensional modeling modeling and ETL/ELT best practices, scalability, complex process management, self-healing approaches, etc","Strong working knowledge in at-least one of the big data architecture such as Lambda, Kappa and Hub and Spoke Architectures","Excellent proficiency in Stream-processing systems like Storm, Spark-Streaming, kafka streaming and building real time data pipelines","Proficiency in Container technologies: Docker, and Kubernetes","Experience with modern Data Replication and Data processing tools such as Qlik, Fivetran","Understanding of data security and privacy regulations, with experience implementing data security best practices","Ability to define and manage user roles and permissions in Snowflake to ensure data security and privacy","Experience in working in a startup-type environment, good team player, and can work independently with minimal supervision","Proficient in managing large volumes of data","Strong analytical and interpersonal skills, comfortable presenting complex ideas in simple terms","Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams","Experience in providing technical support and troubleshooting for data-related issues","Experience with nosql systems such as mongodb, cockroach","Db, apache cassandra etc","Significant experience with open source platforms and technologies"],"Responsibilities":["As a member of the Data & BI Engineering team you will primarily focus on advancing our Enterprise Data Platform to allow the organization to make data-driven decisions","The successful candidate will work closely with cross-functional teams to identify business requirements, design, and develop data models, data warehouses, and data visualization solutions that help support the organization's strategic goals","The Staff Data Engineer will work in a dynamic environment and will be required to stay current with the latest trends and technologies in the business intelligence field","The team is also responsible for administering tools and platforms around reporting, analytics, and data visualization while promoting best practices","Design and build infrastructure for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources, including data identification, mapping, aggregation, conditioning, cleansing, and analyzing","Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc","Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand data requirements and deliver valuable insights","Effectively communicate complex technical concepts to non-technical audiences","Maintain documentation and operational knowledge base","Coach and technically train junior staff on design and development standards and best practices","Design and implement data security and governance protocols to ensure the accuracy and reliability of data"],"Benefits":["USD $147,000.00 - USD $196,000.00","In addition to base pay, BlackLine also offers short-term and long-term incentive programs, based on eligibility, along with a robust offering of benefit and wellness plans"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":null,"job_naics_code":"511210","job_naics_name":"Software Publishers"},{"job_id":"wCxrdnCY8SzoDozbAAAAAA==","employer_name":"Disney Entertainment & ESPN Technology","employer_logo":null,"employer_website":null,"employer_company_type":null,"employer_linkedin":null,"job_publisher":"Jobs And Careers At DISNEY","job_employment_type":"FULLTIME","job_title":"Senior Data Engineer","job_apply_link":"https://jobs.disneycareers.com/job/santa-monica/senior-data-engineer/391/67635083408?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","job_apply_is_direct":false,"job_apply_quality_score":0.8011,"apply_options":[{"publisher":"Jobs And Careers At DISNEY","apply_link":"https://jobs.disneycareers.com/job/santa-monica/senior-data-engineer/391/67635083408?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"LinkedIn","apply_link":"https://www.linkedin.com/jobs/view/senior-data-engineer-at-clickjobs-io-4004303313?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Ladders","apply_link":"https://www.theladders.com/job/senior-data-engineer-thewaltdisneycompany-bristol-ct_73229772?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Dice","apply_link":"https://www.dice.com/job-detail/a8435c58-9f97-4226-9a7d-ce2642276d8f?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Monster","apply_link":"https://www.monster.com/job-openings/senior-data-engineer-bristol-ct--b1fb8ca7-4bb8-4f0d-ba9d-dc7db8fea59b?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"SaluteMyJob","apply_link":"https://salutemyjob.com/jobs/senior-data-engineer-bristol-connecticut/1417253865-2/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false},{"publisher":"Talent.com","apply_link":"https://www.talent.com/view?id=05595d20b4a1&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":true},{"publisher":"IT Jobs For ColU Fans","apply_link":"https://itjobs.cu-fc.com/jobs-for-colu-fans/SENIOR-DATA-ENGINEER-job-in-Bristol-Connecticut-USA/a65ade58757e98a1d6/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic","is_direct":false}],"job_description":"Disney Entertainment & ESPN Technology\n\nOn any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world.\n\nA few reasons why we think you’d love working for Disney Entertainment & ESPN Technology\n• Building the future of Disney’s media business: DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come.\n• Reach & Scale: The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more.\n• Innovation: We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news.\n\nJob Summary\n\nThe Product & Data Engineering team is responsible for end to end development for Disney’s world-class consumer-facing products, including streaming platforms Disney+, Hulu, and ESPN+, and digital products & experiences across ESPN, Marvel, Disney Studios, NatGeo, and ABC News. The team drives innovation at scale for millions of consumers around the world across Apple, Android, Smart TVs, game consoles, and the web, with our platforms powering core experiences like personalization, search, messaging and data.\n\nThe Senior Data Engineer will contribute to the Company’s success by partnering with business, analytics and infrastructure teams to design and build data pipelines to facilitate measuring key performance indicators like spend and conversions for the marketing campaigns . Collaborating across disciplines, they will identify internal/external data sources, design table structure, define ETL strategy & automated Data Quality checks.\n\nResponsibilities\n• Contribute to the design and growth of our Data Products and Data Warehouses around Acquisition marketing spend and Acquisition campaign Performance data.\n• Develop and optimize performant database, data model, integration and ETL in RDBMS and Big Data environments\n• Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions\n• Help define technical requirements and implementation details for the underlying data warehouse and data marts\n• Maintain detailed documentation of your work and changes to support data quality and data governance\n• Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to the customers\n\nMinimum Qualifications\n• 5+ years of data engineering experience\n• Proven experience with at least one major RDBMS (SQL Server, MySQL or Oracle)\n• 3+ years of experience with programming languages (e.g. Python, Pyspark).\n• 3+ years of experience with data orchestration/ETL tools (Airflow, Nifi), preferred\n• Strong SQL skills and ability to create queries to extract and build tables\n• Familiarity with Data Modeling techniques and Data Warehousing standard methodologies and practices\n• Familiarity with Amazon s3 and/or ETL using databricks\n• Familiarity with Scrum and Agile methodologies\n• You are a problem solver with strong attention to detail and excellent analytical and communication skills\n\nRequired Education\n• Bachelor’s Degree in Computer Science, Information Systems or related field, or equivalent work experience.\n\nAdditional Information\n\n#DISNEYTECH\n\nThe hiring range for this position in Santa Monica, CA is $136,038.00 to $182,490.00 per year, in San Francisco, CA is $148,994.00 to $199,870.00 per year, in Seattle, WA is $142,516.00 to $191,180.00 per year, and in New York, NY is $142,516.00 to $191,180.00 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","job_is_remote":false,"job_posted_at_timestamp":1721606400,"job_posted_at_datetime_utc":"2024-07-22T00:00:00.000Z","job_city":"Bristol","job_state":"CT","job_country":"US","job_latitude":41.671764,"job_longitude":-72.94927,"job_benefits":["health_insurance"],"job_google_link":"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+ca,usa&start=0&udm=8#vhid=vt%3D20/docid%3DwCxrdnCY8SzoDozbAAAAAA%3D%3D&vssid=jobs-detail-viewer","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":"false","required_experience_in_months":"60","experience_mentioned":"true","experience_preferred":"true"},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":"true","degree_preferred":"true","professional_certification_mentioned":"false"},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["5+ years of data engineering experience","Proven experience with at least one major RDBMS (SQL Server, MySQL or Oracle)","3+ years of experience with programming languages (e.g. Python, Pyspark)","Strong SQL skills and ability to create queries to extract and build tables","Familiarity with Data Modeling techniques and Data Warehousing standard methodologies and practices","Familiarity with Amazon s3 and/or ETL using databricks","Familiarity with Scrum and Agile methodologies","You are a problem solver with strong attention to detail and excellent analytical and communication skills","Bachelor’s Degree in Computer Science, Information Systems or related field, or equivalent work experience"],"Responsibilities":["Collaborating across disciplines, they will identify internal/external data sources, design table structure, define ETL strategy & automated Data Quality checks","Contribute to the design and growth of our Data Products and Data Warehouses around Acquisition marketing spend and Acquisition campaign Performance data","Develop and optimize performant database, data model, integration and ETL in RDBMS and Big Data environments","Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions","Help define technical requirements and implementation details for the underlying data warehouse and data marts","Maintain detailed documentation of your work and changes to support data quality and data governance","Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to the customers"],"Benefits":["The hiring range for this position in Santa Monica, CA is $136,038.00 to $182,490.00 per year, in San Francisco, CA is $148,994.00 to $199,870.00 per year, in Seattle, WA is $142,516.00 to $191,180.00 per year, and in New York, NY is $142,516.00 to $191,180.00 per year","The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors","A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered"]},"job_job_title":"Senior data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4","job_occupational_categories":null,"job_naics_code":null,"job_naics_name":null}]}
